{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Azure_Data_Lake_Brief_2_04122024","text":""},{"location":"#context","title":"Context","text":"<p>Construire une infrastructure de donn\u00e9es solide et s\u00e9curis\u00e9e sur Microsoft Azure. L'objectif de ce brief autour de la s\u00e9curisation et du monitoring d'un Data Lake.</p> <p>Les objetcifs du brief : - Configurer un Data Lake pour centraliser les donn\u00e9es.  - Ing\u00e9rer des donn\u00e9es provenant de diff\u00e9rentes sources. - Mettre en place des mesures de s\u00e9curit\u00e9 avanc\u00e9es pour prot\u00e9ger les donn\u00e9es sensibles. - Configurer Azure Databricks pour permettre \u00e0 l'\u00e9quipe Data Science d'analyser les donn\u00e9es. - Impl\u00e9menter un syst\u00e8me de monitoring et d'alertes pour surveiller l'infrastructure. - [Bonus] : d\u00e9ployer l'infrastructure via terrafrom.</p>"},{"location":"#pre-requis","title":"Pr\u00e9-requis","text":"<p>Avant de lancer le projet, assurez-vous d'avoir install\u00e9 les outils et d\u00e9pendances suivants:</p> <ol> <li> <p>poetry : un gestionnaire de d\u00e9pendances pour Python. Pour installer Poetry suivre le lien suivant le site officiel de Poetry.</p> </li> <li> <p>Azure CLI : un ensemble d'outils en ligne de commande pour g\u00e9rer les services Azure. le site officiel d'Azure CLI.</p> </li> <li> <p>Terraform : outil d'infrastructure as code, pour cr\u00e9er, g\u00e9rer et versionner des ressources cloud. le site officiel de Terraform.</p> </li> <li> <p>D\u00e9pendance Python : avoir python install\u00e9 le site officiel de Python.</p> </li> <li> <p>D\u00e9pendance Python : pour installer les d\u00e9pendances n\u00e9cessaires pour ce projet avec poetry :</p> </li> </ol> <pre><code>    poetry install\n</code></pre> <ol> <li>Connexion Azure : Connectez-vous \u00e0 votre compte Azure en utilisant Azure CLI avec la commande suivante :</li> </ol> <pre><code>    az login\n</code></pre> <ol> <li>Configuration des variables d'environnement : Cr\u00e9ez un fichier <code>.env</code> \u00e0 la racine du projet et ajoutez les variables d'environnement n\u00e9cessaires pour la configuration du projet:</li> </ol> <pre><code>    AZ_TENANT_ID=&lt;votre_tenant_id&gt;\n    KEY_VAULT_NAME=&lt;votre_key_vault_name&gt;\n    SECRET_NAME_SECONDAIRE=&lt;nom_service_principal_secondaire&gt;\n    SECRET_NAME_PRINCIPAL=&lt;nom_service_principal_principal&gt;\n    SP_CLIENT_ID=&lt;votre_sp_client_id&gt;\n    SP_PRINCIPAL_CLIENT_ID=&lt;votre_sp_principal_client_id&gt;\n    SP_SECONDARY_PASSWORD=&lt;votre_sp_secondary_password&gt;\n    STORAGE_ACCOUNT_NAME=&lt;votre_storage_account_name&gt;\n    CONTAINER_NAME=&lt;votre_container_name&gt;\n    BLOB_NAME=&lt;votre_blob_name&gt;\n    LOCAL_FILE_PATH=&lt;votre_local_file_path&gt;\n    LOCAL_FILE_PATH=&lt;votre_local_file_path_parquet&gt;\n</code></pre> <ol> <li>Lien du repo Github https://DaiTensa.github.io/Azure_Data_Lake_Security/</li> </ol>"},{"location":"partie1/introduction/","title":"Brief Data Lake 2 - 02-12-2024 Ingestion avanc\u00e9e, monitoring, et s\u00e9curit\u00e9","text":""},{"location":"partie1/introduction/#objectif","title":"Objectif","text":"<p>Acqu\u00e9rir une vision panoramique des m\u00e9thodes de s\u00e9curit\u00e9 disponibles sur Azure pour prot\u00e9ger les donn\u00e9es dans un Data Lake. </p> <p>Il y a plusieurs aspects importants concernant les applications et les donn\u00e9es en termes de s\u00e9curit\u00e9 :</p> <ul> <li>Gestion des secrets : Les applications ont besoin d'acc\u00e9der \u00e0 des bases de donn\u00e9es et des services en utilisant des secrets ou des cl\u00e9s API. Si ces informations sont stock\u00e9es en clair ou int\u00e9gr\u00e9es directement dans le code, cela augmente le risque d\u2019acc\u00e8s non autoris\u00e9 en cas de faille de s\u00e9curit\u00e9.</li> <li>Gestion des cl\u00e9s : Essentielle pour prot\u00e9ger les donn\u00e9es sensibles gr\u00e2ce au chiffrement.</li> <li>Gestion des certificats : Les applications communiquent entre elles, donc la gestion des certificats est cruciale pour s\u00e9curiser les communications r\u00e9seau avec des certificats SSL/TLS.</li> </ul> <p>En r\u00e9sum\u00e9, la gestion des secrets, des cl\u00e9s et des certificats est essentielle pour une s\u00e9curit\u00e9 solide. </p> <p>Cela permet de stocker des informations sensibles de mani\u00e8re s\u00e9curis\u00e9e, de contr\u00f4ler les acc\u00e8s et de chiffrer les donn\u00e9es dans les environnements cloud. </p> <p>Ces processus doivent respecter les trois principes du Zero Trust : v\u00e9rifier explicitement, limiter les acc\u00e8s au strict n\u00e9cessaire et supposer qu\u2019une faille est toujours possible. </p> <p>Pour y parvenir, des outils sp\u00e9cialis\u00e9s sont n\u00e9cessaires, comme Azure Key Vault, qui r\u00e9pond \u00e0 ces besoins.</p>"},{"location":"partie1/introduction/#approches-pour-securiser-une-infrastructure","title":"Approches pour s\u00e9curiser une infrastructure","text":""},{"location":"partie1/introduction/#zero-trust","title":"Zero Trust","text":"<p>Dans un syst\u00e8me logiciel, deux composants principaux que sont les applications et les donn\u00e9es. Les applications servent d\u2019interface pour acc\u00e9der aux donn\u00e9es, et les donn\u00e9es sont ce que les \u00e9quipes de s\u00e9curit\u00e9 cherchent avant tout \u00e0 prot\u00e9ger. </p> <p>Ainsi, garantir la s\u00e9curit\u00e9 des applications et des donn\u00e9es est l\u2019un des principaux objectifs du mod\u00e8le Zero Trust.</p> <p>En r\u00e9sum\u00e9 : Zero Trust est une strat\u00e9gie de s\u00e9curit\u00e9.</p> <p>Zero Trust n\u2019est ni un produit ni un service. C\u2019est plut\u00f4t une approche, un cadre, un mod\u00e8le, ou m\u00eame une philosophie de conception des syst\u00e8mes, bas\u00e9e sur un principe simple : ne jamais faire confiance, toujours v\u00e9rifier.</p> <p>Au lieu de supposer que tout ce qui est derri\u00e8re le pare-feu de l\u2019entreprise est s\u00e9curis\u00e9, le mod\u00e8le Zero Trust part du principe qu\u2019une violation est possible et v\u00e9rifie chaque demande comme si elle venait d\u2019une source non fiable. Peu importe d\u2019o\u00f9 provient la demande ou quelle ressource elle veut acc\u00e9der, le mod\u00e8le Zero Trust insiste : ne jamais faire confiance, toujours v\u00e9rifier.</p> <p>Plus pr\u00e9cis\u00e9ment, Zero Trust repose sur trois piliers principaux :</p> <ol> <li>V\u00e9rification explicite : toujours authentifier et autoriser en fonction de toutes les donn\u00e9es disponibles.</li> <li>Acc\u00e8s au moindre privil\u00e8ge : limiter les acc\u00e8s des utilisateurs avec des politiques adapt\u00e9es, comme le Just-In-Time (JIT, acc\u00e8s temporaire) et le **Just-Enough-Access (JEA, acc\u00e8s suffisant), bas\u00e9es sur les risques et la protection des donn\u00e9es.</li> <li>Supposer une violation : minimiser les impacts en segmentant les acc\u00e8s. V\u00e9rifier le chiffrement de bout en bout et utiliser des outils d\u2019analyse pour surveiller, d\u00e9tecter les menaces et renforcer les d\u00e9fenses.</li> </ol> <p>Ce sont les fondements de Zero Trust.</p>"},{"location":"partie1/structure/","title":"Azure Data Lake Project","text":""},{"location":"partie1/structure/#architecture-du-projet","title":"Architecture du projet","text":"<ol> <li> <p>R\u00e9pertoire racine:</p> <ul> <li><code>.env</code></li> <li><code>.gitignore</code></li> <li><code>auth.py</code></li> <li><code>create_project.sh</code></li> <li><code>poetry.lock</code></li> <li><code>pyproject.toml</code></li> <li><code>README.md</code></li> </ul> </li> <li> <p>Configuration Terraform:</p> <ul> <li><code>AZURE_DATA_LAKE_BRIEF_2_04122024/</code><ul> <li><code>.terraform/</code><ul> <li><code>modules/</code></li> <li><code>providers/</code></li> </ul> </li> <li><code>.terraform.lock.hcl</code></li> <li><code>environments/</code><ul> <li><code>dev.tfvars</code></li> <li><code>prod.tfvars</code></li> <li><code>staging.tfvars</code></li> </ul> </li> <li><code>main.tf</code></li> <li><code>modules/</code><ul> <li><code>data_lake/</code></li> <li><code>databricks/</code></li> <li><code>key_vault/</code></li> <li><code>monitoring/</code></li> <li><code>resource_group/</code></li> </ul> </li> <li><code>outputs.tf</code></li> <li><code>plan.tfplan</code></li> <li><code>provider.tf</code></li> <li><code>terraform.tfstate</code></li> <li><code>terraform.tfstate.backup</code></li> <li><code>terraform.tfvars</code></li> <li><code>variables.tf</code></li> </ul> </li> </ul> </li> <li> <p>Documentation:</p> <ul> <li><code>docs/</code><ul> <li><code>docs/</code><ul> <li><code>images/</code></li> <li><code>about.md</code></li> <li><code>analytics.md</code></li> <li><code>index.md</code></li> <li><code>installation.md</code></li> <li><code>security.md</code></li> <li><code>storage.md</code></li> <li><code>structure.md</code></li> </ul> </li> <li><code>mkdocs.yml</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"partie1/structure/#composants-cles","title":"Composants cl\u00e9s:","text":"<ul> <li> <p>Terraform Modules:</p> <ul> <li><code>resource_group</code>: Manages Azure Resource Groups.</li> <li><code>data_lake</code>: G\u00e8re Azure Data Lake Storage.</li> <li><code>key_vault</code>: G\u00e8re Azure Key Vault.</li> <li><code>databricks</code>: G\u00e8re l'espace de travail Azure Databricks.</li> <li><code>monitoring</code>: G\u00e8re les ressources de surveillance.</li> </ul> </li> <li> <p>Terraform State and Configuration:</p> <ul> <li><code>main.tf</code>: Fichier de configuration principal Terraform.</li> <li><code>variables.tf</code>: D\u00e9finit les variables d'entr\u00e9e.</li> <li><code>outputs.tf</code>: D\u00e9finit les valeurs de sortie.</li> <li><code>provider.tf</code>: Configure les fournisseurs Terraform.</li> <li><code>terraform.tfvars</code>: D\u00e9finit les valeurs des variables.</li> <li><code>terraform.tfstate</code>: Stocke l'\u00e9tat de l'infrastructure.</li> <li><code>terraform.tfstate.backup</code>: Sauvegarde du fichier d'\u00e9tat.</li> <li><code>plan.tfplan</code>: Plan d'ex\u00e9cution pour Terraform.</li> </ul> </li> <li> <p>Documentation:</p> <ul> <li><code>mkdocs.yml</code>: Configuration pour MkDocs.</li> <li><code>about.md</code>, <code>analytics.md</code>, <code>index.md</code>: Fichiers de documentation.</li> </ul> </li> </ul>"},{"location":"partie1/veille/","title":"Veille syst\u00e8mes de s\u00e9curit\u00e9","text":""},{"location":"partie1/veille/#partie-1-veille-sur-les-systemes-de-securite","title":"Partie 1 : Veille sur les Syst\u00e8mes de S\u00e9curit\u00e9","text":""},{"location":"partie1/veille/#iam-et-role-based-access-control-rbac","title":"IAM et Role-Based Access Control (RBAC)","text":""},{"location":"partie1/veille/#iam-identity-and-access-management","title":"IAM (Identity and Access Management)","text":"<p>Un Ensemble de r\u00e8gles et de technologies qui garantit que les bonnes personnes au sein d'une organisation ont les acc\u00e8s appropri\u00e9s. cela consiste \u00e0 g\u00e9rer qui peut acc\u00e9der \u00e0 quoi (un utilisateur, un groupes d'utilisateurs, services) en contr\u00f4lant l'acc\u00e8s et les interactions avec les ressources dans le cloud. </p>"},{"location":"partie1/veille/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Au coeur de nombreux syst\u00e8mes IAM se trouve le contr\u00f4le d\u2019acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC), une m\u00e9thode permettant de g\u00e9rer l'acc\u00e8s des utilisateurs au ressources informatiques ou r\u00e9seau en fonction des r\u00f4les des individus au sein de l'organisation. Les autorisations sont regroup\u00e9es dans des r\u00f4les, les utilisateurs sont ensuite affect\u00e9s \u00e0 ces r\u00f4les en fonction de leurs fonctions dans l'entreprise, les autorisations n'ont pas besoin d'\u00eatre attribu\u00e9es individuellement \u00e0 chaque utilisateur.</p> <p>Il existe une autre m\u00e9thode pour g\u00e9rer les acc\u00e8s, il s'agit du mod\u00e8le d'acc\u00e8s ACL (Liste de Contr\u00f4le d'Acc\u00e9s), choisir entre RBAC ou ACL d\u00e9pend du niveau de pr\u00e9cision requis. RBAC est souvent suffisant pour g\u00e9rer les autorisations, tandis que les ACL offrent un contr\u00f4le plus pr\u00e9cis lorsuqe c'est n\u00e9cessaire.</p> <p>ACL : offre un contr\u00f4le plus pr\u00e9cis, permet de sp\u00e9cifier des autorisations d'acc\u00e8s pour des objets individuels au sein d'un service, exemple Contr\u00f4ler quels utilisateurs peuvent lire ou \u00e9crire des fichiers ou dossiers sp\u00e9cifiques dans Azure Storage.</p> <p></p>"},{"location":"partie1/veille/#microsoft-entra-id","title":"Microsoft Entra ID","text":"<p>Anciennement appel\u00e9 Azure Active Directory (Azure AD), est le service de gestion des identit\u00e9s et des acc\u00e8s (IAM).</p> <p>Permet de g\u00e9rer les utilisateurs, les groupes et les applications, tout en s\u00e9curisant l'acc\u00e8s aux ressources dans azure cloud, (on-premises) et m\u00eame dans des environnements hybrides.</p>"},{"location":"partie1/veille/#azure-key-vault","title":"Azure  Key Vault","text":"<p>Un service qui permet de stocker et d'acc\u00e9der de mani\u00e8re s\u00e9curis\u00e9 \u00e0 des secrets, comme des mots de passe, des cl\u00e9s API, et des certificats, bien qu'il s'agisse d'un service distinct de Microsoft Entra ID, ils fonctionnent ensemble pour offrir une s\u00e9curit\u00e9 renforc\u00e9e \u00e0 vos informations sensible</p> <p>Azure Key Vault une plateforme robuste pour g\u00e9rer toute donn\u00e9es sensible, et prot\u00e9ger les informations critiques.</p> <p>Azure Key Vault peut stocker diff\u00e9rents type d'infromations sensibles, les pricnipaux types de secrets : - Mots de passe : stocker en toute s\u00e9curit\u00e9 les mots de passes pour les applications, bases de donn\u00e9es, et autres services. - Cl\u00e9s API : G\u00e9rer les cl\u00e9s d'API pour acc\u00e9der \u00e0 des services externes. - Certificats : certificats SSL/TLS pour des sites web et des applications, simplifiant leur gestion et garantissant une communication s\u00e9curis\u00e9e. - Cha\u00eene de connexion (Connection String) : stocker de mani\u00e8re s\u00e9curis\u00e9 les cha\u00eenes de connexion pour des bases de donn\u00e9es, des files d'attentes de messages et d'autres services. - Secrets personnalis\u00e9s : Stocker tout type de donn\u00e9es sensibles sous frome de secret personnalis\u00e9 (avec une certaine limite de taille)</p> <p>Voici pourquoi envisager d'utiliser Azure Key Vault :</p> <ul> <li>Authentification et autorisation s\u00e9curis\u00e9es : Key Vault s\u2019appuie sur Azure Active Directory et les r\u00f4les Azure RBAC pour garantir un contr\u00f4le d\u2019acc\u00e8s pr\u00e9cis.</li> <li>Protection des cl\u00e9s et secrets : Ils peuvent \u00eatre prot\u00e9g\u00e9s par logiciel ou mat\u00e9riel (via des modules HSM) pour une s\u00e9curit\u00e9 renforc\u00e9e.</li> <li>Administration simplifi\u00e9e : Key Vault offre une gestion facile et une haute disponibilit\u00e9 gr\u00e2ce \u00e0 la r\u00e9plication des donn\u00e9es.</li> <li>Surveillance des acc\u00e8s : Vous pouvez activer la journalisation pour suivre les acc\u00e8s et les actions effectu\u00e9es.</li> <li>Int\u00e9gration native avec les services Azure : Key Vault s\u2019int\u00e8gre parfaitement avec des services comme Azure Disk Encryption, SQL Server et Azure App Service, ce qui simplifie son utilisation dans les environnements Azure.</li> </ul> <p>C\u2019est une solution compl\u00e8te pour s\u00e9curiser et g\u00e9rer les secrets et cl\u00e9s dans le cloud.</p>"},{"location":"partie1/veille/#storage-access-keys","title":"Storage Access Keys","text":"<p>Essentiels pour prot\u00e9ger les donn\u00e9es.</p> <p>Chaque compte de stockage dispose g\u00e9n\u00e9ralement de deux cl\u00e9s d'acc\u00e8s : Une cl\u00e9 principale et une cl\u00e9 secondaire. Cela offre une s\u00e9curit\u00e9 et une flexibilit\u00e9 suppl\u00e9mentaires. </p> <p>Par exemple, utiliser la cl\u00e9 principale les op\u00e9rations courantes et conserver la cl\u00e9 secondaire comme sauvegarde au cas o\u00f9 la cl\u00e9 principale serait compromise.</p> <p>Il est crucial de garder ces cl\u00e9s secr\u00e8tes et de les manipuler avec pr\u00e9caution. Il faut \u00e9viter de les stocker directement dans code ou dans les fichiers de configuration. Il est conseiller d'utiliser des solutions de stockage s\u00e9curis\u00e9 comme Azure Key Vault.</p> <p>La rotation r\u00e9guli\u00e8re des cl\u00e9s r\u00e9duit la p\u00e9riode de vuln\u00e9rabilit\u00e9 en cas de compromission. Plus une cl\u00e9 est utilis\u00e9e longtemps, plus le risque qu'elle soit accidentellement expos\u00e9e ou vol\u00e9e augmente. En les changeant fr\u00e9quemment, on rend plus difficile l'acc\u00e8s prolong\u00e9 de personnes non autoris\u00e9es aux donn\u00e9es.</p>"},{"location":"partie1/veille/#shared-access-signatures-sas-delegation-key","title":"Shared Access Signatures (SAS) (Delegation Key)","text":"<p>Les Shared Access Signatures (SAS), en particulier celles utilisant des cl\u00e9s de d\u00e9l\u00e9gation utilisateur, offrent un moyen puissant de donner un acc\u00e8s limit\u00e9 et contr\u00f4l\u00e9 aux ressources Azure Storage sans partager les cl\u00e9s d'acc\u00e8s au compte. Il s'agit de d\u00e9livrer des cl\u00e9s d'acc\u00e8s temporaires au compte de stockage.</p> <p>Avec les User Delegation SAS, permettent de d\u00e9finir des niveaux d\u2019acc\u00e8s pr\u00e9cis, comme lecture, \u00e9criture ou liste, pour des ressources sp\u00e9cifiques comme des blobs, des conteneurs ou des files d\u2019attente. </p> <p>De plus, on peut d\u00e9finir des dates d\u2019expiration pour que l\u2019acc\u00e8s soit automatiquement r\u00e9voqu\u00e9 apr\u00e8s une certaine p\u00e9riode. Cela permet un contr\u00f4le pr\u00e9cis de l\u2019acc\u00e8s aux donn\u00e9es et une meilleure s\u00e9curit\u00e9.</p>"},{"location":"partie1/veille/#types-de-jetons-sas-shared-access-signatures","title":"Types de jetons SAS (Shared Access Signatures)","text":""},{"location":"partie1/veille/#service-sas","title":"Service SAS","text":"<p>Ce type de SAS donne acc\u00e8s \u00e0 un service de stockage sp\u00e9cifique, comme Blob, Queue, Table ou File. Il permet de d\u00e9l\u00e9guer l\u2019acc\u00e8s \u00e0 une ressource particuli\u00e8re au sein du service, par exemple un blob ou un conteneur sp\u00e9cifique.</p>"},{"location":"partie1/veille/#account-sas","title":"Account SAS","text":"<p>Un Account SAS offre un acc\u00e8s plus large, permettant de d\u00e9l\u00e9guer l\u2019acc\u00e8s \u00e0 plusieurs services de stockage au sein d\u2019un m\u00eame compte. Il est g\u00e9n\u00e9ralement utilis\u00e9 dans des sc\u00e9narios o\u00f9 un acc\u00e8s \u00e0 un \u00e9ventail plus large de ressources est n\u00e9cessaire.</p>"},{"location":"partie1/veille/#user-delegation-sas","title":"User Delegation SAS","text":"<p>Ce type de SAS, utilise les identifiants Azure AD pour l\u2019authentification. Il permet de fournir un acc\u00e8s bas\u00e9 sur l\u2019identit\u00e9 et les permissions de l\u2019utilisateur dans Azure AD, offrant un contr\u00f4le pr\u00e9cis sur l\u2019acc\u00e8s aux donn\u00e9es.</p>"},{"location":"partie1/veille/#service-principal","title":"Service Principal","text":"<p>En termes simples, un service principal est un outil dot\u00e9 d'une identit\u00e9, cr\u00e9\u00e9 et g\u00e9r\u00e9 au plus haut niveau dans un annuaire, tout comme les utilisateurs. Lorsqu'un service principal est cr\u00e9\u00e9, une relation de confiance \u00e0 sens unique est \u00e9tablie entre ce service principal et la plateforme d'identit\u00e9 Azure.</p>"},{"location":"partie2/deploiement/","title":"D\u00e9ploiement de l'Infrastructure avec Terraform","text":""},{"location":"partie2/deploiement/#prerequis","title":"Pr\u00e9requis","text":"<p>Avant de commencer, assurez-vous d'avoir les \u00e9l\u00e9ments suivants install\u00e9s sur votre machine :</p> <ul> <li>Terraform</li> <li>Azure CLI</li> </ul>"},{"location":"partie2/deploiement/#etapes-pour-lancer-terraform-et-deployer-linfrastructure","title":"\u00c9tapes pour lancer Terraform et d\u00e9ployer l'infrastructure","text":"<p>Cloner le d\u00e9p\u00f4t</p> <pre><code>git clone https://github.com/DaiTensa/Azure_Data_Lake_Brief_2_04122024.git\n</code></pre> <pre><code>cd Azure_Data_Lake_Brief_2_04122024\n</code></pre> <p>Configurer les variables</p> <p>Cr\u00e9ez un fichier <code>terraform.tfvars</code></p> <pre><code>touch terraform.tfvars\n</code></pre> <p>Puis ajoutez les valeurs n\u00e9cessaires pour le d\u00e9ploiement de l'infrastructure:</p> <pre><code>rg_name        = &lt;nom_du_resource_groupe&gt;\nrg_location    = &lt;location_geographique&gt;\nstorage_account = &lt;nom_storage_account&gt;\nkv_name        = &lt;nom_key_vault&gt;\nsubscription_id = &lt;qubqcription_azure_id&gt;\ninitial_firstname = &lt;initial_prenom&gt;\nlastname = &lt;nom&gt;\n</code></pre> <p>Initialiser Terraform</p> <pre><code>terraform init\n</code></pre> <p>Planifier le d\u00e9ploiement</p> <pre><code>terraform plan -var-file=\"terraform.tfvars\" -out=\"plan.tfplan\"\n</code></pre> <p>Cette commande g\u00e9n\u00e8re un plan d'ex\u00e9cution et l'enregistre dans un fichier nomm\u00e9 <code>plan</code>.</p> <p>Appliquer le plan</p> <pre><code>terraform apply \"plan.tfplan\"\n</code></pre> <p>Cette commande applique les modifications n\u00e9cessaires pour atteindre l'\u00e9tat d\u00e9crit dans le plan.</p> <p>V\u00e9rifier le d\u00e9ploiement</p> <p>Une fois le d\u00e9ploiement termin\u00e9, vous pouvez v\u00e9rifier les ressources cr\u00e9\u00e9es dans le portail Azure ou en utilisant l'Azure CLI.</p>"},{"location":"partie2/deploiement/#nettoyage","title":"Nettoyage","text":"<p>Pour d\u00e9truire l'infrastructure cr\u00e9\u00e9e, utilisez la commande suivante :</p> <pre><code>terraform destroy\n</code></pre> <p>Cela supprimera toutes les ressources g\u00e9r\u00e9es par votre configuration Terraform.</p>"},{"location":"partie2/deploiement/#notice","title":"Notice","text":"<ul> <li>Assurez-vous de bien configurer vos variables dans le fichier <code>terraform.tfvars</code>.</li> </ul>"},{"location":"partie2/infrastructure/","title":"Sorties du Code Terraform","text":"<p>Les sorties g\u00e9n\u00e9r\u00e9es par le code Terraform dans le fichier <code>main.tf</code>. Ce fichier appelle plusieurs modules pour cr\u00e9er et configurer des ressources Azure.</p>"},{"location":"partie2/infrastructure/#modules-utilises","title":"Modules Utilis\u00e9s","text":""},{"location":"partie2/infrastructure/#module-resource_group","title":"Module <code>resource_group</code>","text":"<p>Ce module cr\u00e9e un groupe de ressources Azure.</p> <ul> <li>Entr\u00e9es :</li> <li><code>rg_name</code> : Nom du groupe de ressources.</li> <li> <p><code>rg_location</code> : Emplacement du groupe de ressources.</p> </li> <li> <p>Sorties :</p> </li> <li><code>rg_name</code> : Nom du groupe de ressources cr\u00e9\u00e9.</li> </ul>"},{"location":"partie2/infrastructure/#module-data_lake","title":"Module <code>data_lake</code>","text":"<p>Ce module cr\u00e9e un compte de stockage Azure Data Lake et des conteneurs de stockage.</p> <ul> <li>Entr\u00e9es :</li> <li><code>rg_name</code> : Nom du groupe de ressources.</li> <li><code>storage_account</code> : Nom du compte de stockage.</li> <li><code>location</code> : Emplacement du compte de stockage.</li> <li> <p><code>container_names</code> : Liste des noms des conteneurs \u00e0 cr\u00e9er.</p> </li> <li> <p>Sorties :</p> </li> <li><code>storage_account_id</code> : ID du compte de stockage cr\u00e9\u00e9.</li> </ul>"},{"location":"partie2/infrastructure/#module-key_vault","title":"Module <code>key_vault</code>","text":"<p>Ce module cr\u00e9e un Azure Key Vault et configure les acc\u00e8s pour les Service Principals.</p> <ul> <li>Entr\u00e9es :</li> <li><code>rg_name</code> : Nom du groupe de ressources.</li> <li><code>kv_name</code> : Nom du Key Vault.</li> <li><code>location</code> : Emplacement du Key Vault.</li> <li><code>initial_firstname</code> : Pr\u00e9nom de l'utilisateur initial.</li> <li><code>lastname</code> : Nom de famille de l'utilisateur initial.</li> <li> <p><code>storage_account_id</code> : ID du compte de stockage (provenant du module <code>data_lake</code>).</p> </li> <li> <p>Sorties :</p> </li> <li><code>key_vault_id</code> : ID du Key Vault cr\u00e9\u00e9.</li> </ul>"},{"location":"partie2/infrastructure/#module-databricks","title":"Module <code>databricks</code>","text":"<p>Ce module cr\u00e9e et configure un workspace Azure Databricks.</p> <ul> <li>Entr\u00e9es :</li> <li><code>rg_name</code> : Nom du groupe de ressources.</li> <li> <p><code>location</code> : Emplacement du workspace Databricks.</p> </li> <li> <p>Sorties :</p> </li> <li><code>databricks_workspace_id</code> : ID du workspace Databricks cr\u00e9\u00e9.</li> </ul>"},{"location":"partie2/infrastructure/#module-monitoring","title":"Module <code>monitoring</code>","text":"<p>Ce module configure la surveillance et le monitoring des ressources Azure.</p> <ul> <li>Entr\u00e9es :</li> <li><code>rg_name</code> : Nom du groupe de ressources.</li> <li> <p><code>location</code> : Emplacement des ressources de monitoring.</p> </li> <li> <p>Sorties :</p> </li> <li><code>monitoring_workspace_id</code> : ID du workspace de monitoring cr\u00e9\u00e9.</li> </ul>"},{"location":"partie2/infrastructure/#resume-des-sorties","title":"R\u00e9sum\u00e9 des Sorties","text":"<p>Apr\u00e8s l'ex\u00e9cution du code Terraform, les sorties suivantes seront disponibles :</p> <ul> <li><code>resource_group.rg_name</code> : Nom du groupe de ressources cr\u00e9\u00e9.</li> <li><code>data_lake.storage_account_id</code> : ID du compte de stockage Azure Data Lake cr\u00e9\u00e9.</li> <li><code>key_vault.key_vault_id</code> : ID du Key Vault cr\u00e9\u00e9.</li> <li><code>databricks.databricks_workspace_id</code> : ID du workspace Databricks cr\u00e9\u00e9.</li> <li><code>monitoring.monitoring_workspace_id</code> : ID du workspace de monitoring cr\u00e9\u00e9.</li> </ul> <p>Le code Terraform dans <code>main.tf</code> appelle plusieurs modules pour cr\u00e9er et configurer des ressources Azure. Les sorties g\u00e9n\u00e9r\u00e9es par ces modules fournissent des informations essentielles sur les ressources cr\u00e9\u00e9es, permettant une gestion et une configuration efficaces de l'infrastructure.</p>"},{"location":"partie2/ingestion/","title":"Ingestion de Donn\u00e9es dans Azure Data Lake","text":"<p>Comment uploader des donn\u00e9es dans le datalake gen2</p> <p><code>upload_file_to_dl.py</code> pour ing\u00e9rer des fichiers CSV ou Parquet dans Azure Data Lake de mani\u00e8re s\u00e9curis\u00e9e en utilisant des Service Principals (SP) et des SAS tokens.</p>"},{"location":"partie2/ingestion/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li>Python 3.12 ou sup\u00e9rieur</li> <li>Les biblioth\u00e8ques Python suivantes :</li> <li><code>python-dotenv</code></li> <li><code>azure-identity</code></li> <li><code>azure-keyvault-secrets</code></li> <li><code>azure-storage-blob</code></li> <li>Un compte Azure avec les services suivants configur\u00e9s :</li> <li>Azure Key Vault</li> <li>Azure Storage Account</li> <li>Deux Service Principals configur\u00e9s avec les r\u00f4les et permissions n\u00e9cessaires</li> </ul>"},{"location":"partie2/ingestion/#configuration","title":"Configuration","text":"<ol> <li>Cr\u00e9ez un fichier <code>.env</code> \u00e0 la racine du projet avec les variables d'environnement suivantes :</li> </ol> <pre><code>    KEY_VAULT_NAME=&lt;votre_nom_de_key_vault&gt;\n    AZ_TENANT_ID=&lt;votre_tenant_id&gt;\n    SP_CLIENT_ID=&lt;votre_client_id_secondaire&gt;\n    SP_PRINCIPAL_CLIENT_ID=&lt;votre_client_id_principal&gt;\n    SECRET_NAME_PRINCIPAL=&lt;nom_du_secret_principal&gt;\n    STORAGE_ACCOUNT_NAME=&lt;nom_du_storage_account&gt;\n    CONTAINER_NAME=&lt;nom_du_conteneur&gt;\n    BLOB_NAME=&lt;nom_du_blob&gt;\n    LOCAL_FILE_PATH=&lt;chemin_vers_le_fichier_local&gt;\n    SP_SECONDARY_PASSWORD=&lt;mot_de_passe_du_sp_secondaire&gt;\n</code></pre>"},{"location":"partie2/ingestion/#utilisation","title":"Utilisation","text":""},{"location":"partie2/ingestion/#niveau-1-ingestion-de-donnees-csv","title":"Niveau 1 - Ingestion de Donn\u00e9es CSV","text":"<ol> <li> <p>T\u00e9l\u00e9chargez le fichier CSV de <code>reviews.csv</code> et placez-le \u00e0 l'emplacement sp\u00e9cifi\u00e9 par <code>LOCAL_FILE_PATH</code> dans le fichier <code>.env</code></p> </li> <li> <p>Ex\u00e9cutez le script <code>upload.sh</code></p> <p><code>sh ./upload.sh</code></p> </li> </ol> <p>Le script effectuera les op\u00e9rations suivantes :</p> <ul> <li>Charger les variables d'environnement depuis le fichier <code>.env</code></li> <li>Authentifier le Service Principal secondaire pour r\u00e9cup\u00e9rer le secret du Service Principal principal depuis Azure Key Vault.</li> <li>Authentifier le Service Principal principal en utilisant le secret r\u00e9cup\u00e9r\u00e9.</li> <li>G\u00e9n\u00e9rer un SAS token pour le blob sp\u00e9cifi\u00e9.</li> <li>T\u00e9l\u00e9charger le fichier local vers le blob dans Azure Storage Account en utilisant le SAS token.</li> </ul>"},{"location":"partie2/ingestion/#niveau-1-ingestion-de-donnees-parquet","title":"Niveau 1 - Ingestion de Donn\u00e9es Parquet","text":"<p>Pour ing\u00e9rer un fichier Parquet, suivez les m\u00eames \u00e9tapes que pour le fichier CSV, en rempla\u00e7ant simplement le fichier CSV par un fichier Parquet et en mettant \u00e0 jour la variable <code>LOCAL_FILE_PATH</code> dans le fichier <code>.env</code> pour pointer vers le fichier Parquet.</p>"},{"location":"partie2/ingestion/#fonctionnement-du-script","title":"Fonctionnement du Script","text":""},{"location":"partie2/ingestion/#fonctions-principales","title":"Fonctions Principales","text":"<ul> <li><code>load_env()</code>: Charge les variables d'environnement depuis le fichier <code>.env</code>.</li> <li><code>authenticate_client(tenant_id, client_id, client_secret)</code> : Authentifie un client Azure en utilisant les informations d'identification fournies.</li> <li><code>get_secret_from_keyvault(vault_url, secret_name, credential)</code> : R\u00e9cup\u00e8re un secret depuis Azure Key Vault.</li> <li><code>generate_sas_token(storage_account_name, container_name, blob_name, credential)</code> : G\u00e9n\u00e8re un SAS token pour un blob dans Azure Storage Account.</li> <li><code>upload_file(blob_url, local_file_path)</code> : T\u00e9l\u00e9charge un fichier local vers un blob en utilisant l'URL du blob avec le SAS token.</li> </ul>"},{"location":"partie2/ingestion/#fonction-main","title":"Fonction <code>main()</code>","text":"<p>La fonction <code>main()</code> orchestre les \u00e9tapes suivantes :</p> <ol> <li>Charger la configuration depuis les variables d'environnement.</li> <li>Authentifier le Service Principal secondaire pour r\u00e9cup\u00e9rer le secret du Service Principal principal.</li> <li>Authentifier le Service Principal principal en utilisant le secret r\u00e9cup\u00e9r\u00e9.</li> <li>G\u00e9n\u00e9rer un SAS token pour le blob sp\u00e9cifi\u00e9.</li> <li>T\u00e9l\u00e9charger le fichier local vers le blob en utilisant le SAS token.</li> </ol> <p>Le script <code>upload_file_to_dl.py</code> permet d'ing\u00e9rer des fichiers CSV et Parquet dans Azure Data Lake de mani\u00e8re s\u00e9curis\u00e9e en utilisant des Service Principals et des SAS tokens. Assurez-vous de configurer correctement les variables d'environnement et les permissions des Service Principals pour garantir le bon fonctionnement du script.</p>"},{"location":"partie2/introduction/","title":"Introduction","text":"<p>L\u2019objectif de cette partie est de cr\u00e9er des scripts Python pour stocker des donn\u00e9es dans un Azure Data Lake Storage Gen 2 de mani\u00e8re s\u00e9curis\u00e9e. </p> <p>Nous allons g\u00e9rer des identit\u00e9s et des secrets en utilisant des outils comme Azure Key Vault, tout en pratiquant les concepts de s\u00e9curit\u00e9 avec Azure.</p> <p></p>"},{"location":"partie2/security/","title":"Strat\u00e9gie de S\u00e9curit\u00e9","text":"<p>Cette partie d\u00e9crit la strat\u00e9gie de s\u00e9curit\u00e9 mise en place pour le projet Azure Data Lake Brief 2, les r\u00f4les des Service Principals (SP) et justifie les permissions attribu\u00e9es \u00e0 chaque SP.</p>"},{"location":"partie2/security/#roles-des-service-principals","title":"R\u00f4les des Service Principals","text":""},{"location":"partie2/security/#sp-principal-sp_primary_p1","title":"SP Principal (sp_primary_p1)","text":"<p>Le Service Principal principal (<code>sp_primary_p1</code>) est utilis\u00e9 pour g\u00e9rer les op\u00e9rations critiques sur le Data Lake et le Key Vault. Les r\u00f4les et permissions attribu\u00e9s \u00e0 ce SP sont les suivants :</p> <ul> <li>DataLakeUserDelegationRole : Ce r\u00f4le personnalis\u00e9 permet de g\u00e9n\u00e9rer des User Delegation Keys et de manipuler les fichiers dans le Data Lake. Les actions autoris\u00e9es incluent :</li> <li>G\u00e9n\u00e9ration de User Delegation Keys</li> <li> <p>Lecture, \u00e9criture et suppression des conteneurs de blobs</p> </li> <li> <p>Storage Blob Delegator : Ce r\u00f4le permet au SP de d\u00e9l\u00e9guer l'acc\u00e8s aux blobs dans le Storage Account.</p> </li> <li> <p>Storage Blob Data Contributor : Ce r\u00f4le permet au SP de lire, \u00e9crire et supprimer des blobs dans le Storage Account.</p> </li> <li> <p>Key Vault Secrets User : Ce r\u00f4le permet au SP d'acc\u00e9der aux secrets stock\u00e9s dans le Key Vault.</p> </li> <li> <p>Key Vault Contributor : Ce r\u00f4le permet au SP de g\u00e9rer les ressources du Key Vault.</p> </li> <li> <p>Storage Account Key Operator Service Role : Ce r\u00f4le permet au SP de g\u00e9rer les cl\u00e9s du Storage Account.</p> </li> </ul>"},{"location":"partie2/security/#sp-secondaire-sp_secondary_s1","title":"SP Secondaire (sp_secondary_s1)","text":"<p>Le Service Principal secondaire (<code>sp_secondary_s1</code>) est utilis\u00e9 pour des op\u00e9rations moins critiques mais n\u00e9cessaires pour le bon fonctionnement du projet. Les r\u00f4les et permissions attribu\u00e9s \u00e0 ce SP sont les suivants :</p> <ul> <li> <p>Key Vault Secrets User : Ce r\u00f4le permet au SP d'acc\u00e9der aux secrets stock\u00e9s dans le Key Vault.</p> </li> <li> <p>Key Vault Contributor : Ce r\u00f4le permet au SP de g\u00e9rer les ressources du Key Vault.</p> </li> <li> <p>Reader : Ce r\u00f4le permet au SP de lire les ressources du Key Vault.</p> </li> </ul>"},{"location":"partie2/security/#justification-des-permissions","title":"Justification des Permissions","text":""},{"location":"partie2/security/#permissions-du-sp-principal","title":"Permissions du SP Principal","text":"<ul> <li> <p>DataLakeUserDelegationRole : Les permissions de ce r\u00f4le sont n\u00e9cessaires pour permettre au SP principal de g\u00e9rer les User Delegation Keys et de manipuler les fichiers dans le Data Lake, ce qui est essentiel pour les op\u00e9rations de stockage et de gestion des donn\u00e9es.</p> </li> <li> <p>Storage Blob Delegator et Storage Blob Data Contributor : Ces r\u00f4les permettent au SP principal de g\u00e9rer les blobs dans le Storage Account, ce qui est crucial pour les op\u00e9rations de lecture, \u00e9criture et suppression des donn\u00e9es.</p> </li> <li> <p>Key Vault Secrets User et Key Vault Contributor : Ces r\u00f4les permettent au SP principal de g\u00e9rer et d'acc\u00e9der aux secrets dans le Key Vault, assurant ainsi la s\u00e9curit\u00e9 et la gestion des informations sensibles.</p> </li> <li> <p>Storage Account Key Operator Service Role : Ce r\u00f4le permet au SP principal de g\u00e9rer les cl\u00e9s du Storage Account, ce qui est n\u00e9cessaire pour s\u00e9curiser l'acc\u00e8s aux donn\u00e9es stock\u00e9es.</p> </li> </ul>"},{"location":"partie2/security/#permissions-du-sp-secondaire","title":"Permissions du SP Secondaire","text":"<ul> <li> <p>Key Vault Secrets User et Key Vault Contributor : Ces r\u00f4les permettent au SP secondaire de g\u00e9rer et d'acc\u00e9der aux secrets dans le Key Vault, assurant ainsi la s\u00e9curit\u00e9 et la gestion des informations sensibles.</p> </li> <li> <p>Reader : Ce r\u00f4le permet au SP secondaire de lire les ressources du Key Vault, ce qui est n\u00e9cessaire pour les op\u00e9rations de lecture des secrets et des configurations.</p> </li> </ul>"},{"location":"partie2/security/#bonnes-pratiques-de-securite","title":"Bonnes Pratiques de S\u00e9curit\u00e9","text":"<p>La strat\u00e9gie de s\u00e9curit\u00e9 mise en place utilise des Service Principals avec des r\u00f4les et des permissions sp\u00e9cifiques pour assurer la s\u00e9curit\u00e9 et la gestion efficace des ressources Azure. Les permissions attribu\u00e9es sont justifi\u00e9es par les besoins op\u00e9rationnels du projet et visent \u00e0 minimiser les risques de s\u00e9curit\u00e9 tout en permettant une gestion efficace des ressources.</p>"},{"location":"partie2/security/#principe-du-moindre-privilege","title":"Principe du moindre privil\u00e8ge","text":"<ul> <li>Chaque SP a des r\u00f4les sp\u00e9cifiques \u00e0 ses besoins</li> <li>Permissions minimales requises</li> </ul>"},{"location":"partie2/security/#separation-des-responsabilites","title":"S\u00e9paration des responsabilit\u00e9s","text":"<ul> <li>SP Principal : Gestion globale</li> <li>SP Secondaire : Acc\u00e8s limit\u00e9</li> <li>SP Databricks : D\u00e9di\u00e9 \u00e0 Databricks</li> </ul>"},{"location":"partie2/security/#gestion-des-secrets","title":"Gestion des secrets","text":"<ul> <li>Stockage centralis\u00e9 dans Key Vault</li> <li>Rotation automatique des secrets</li> <li>Dates d'expiration d\u00e9finies</li> </ul>"},{"location":"partie2/security/#tracabilite","title":"Tra\u00e7abilit\u00e9","text":"<ul> <li>Nommage explicite des ressources</li> <li>Utilisation des tags</li> <li>D\u00e9pendances explicites</li> </ul>"},{"location":"partie2/security/#maintenance-et-surveillance","title":"Maintenance et Surveillance","text":""},{"location":"partie2/security/#points-de-surveillance","title":"Points de surveillance","text":"<ul> <li>Dates d'expiration des secrets</li> <li>Utilisation des permissions</li> <li>Acc\u00e8s aux ressources</li> </ul>"},{"location":"partie2/security/#taches-de-maintenance","title":"T\u00e2ches de maintenance","text":"<ul> <li>Renouvellement des secrets</li> <li>R\u00e9vision des permissions</li> <li>Mise \u00e0 jour des r\u00f4les</li> </ul>"},{"location":"partie3/deploiement/","title":"Configuration du Cluster Databricks","text":"<p>La configuration et le d\u00e9ploiement d'un cluster Databricks via Terraform.</p>"},{"location":"partie3/deploiement/#structure-du-code","title":"Structure du Code","text":"<p>Le code est organis\u00e9 dans le dossier <code>Databricks_cluster_analysis/databricks/</code> et contient la configuration n\u00e9cessaire pour d\u00e9ployer un cluster Databricks avec des param\u00e8tres sp\u00e9cifiques.</p>"},{"location":"partie3/deploiement/#variables-requises","title":"Variables Requises","text":"<p>Les variables suivantes doivent \u00eatre d\u00e9finies dans votre fichier <code>terraform.tfvars</code> :</p> <pre><code>// filepath: terraform.tfvars\nsp_client_id     = \"votre_client_id\"\nsp_secret_value  = \"votre_secret\"\nsp_tenant_id     = \"votre_tenant_id\"\nworkspace_url    = \"votre_workspace_url\"\ninitial_firstname = \"v\"\nlastname         = \"nom\"\n</code></pre> Variable Description Type <code>sp_client_id</code> ID du Service Principal Azure string <code>sp_secret_value</code> Cl\u00e9 secr\u00e8te du Service Principal string <code>sp_tenant_id</code> ID du tenant Azure string <code>workspace_url</code> URL du workspace Databricks string <code>initial_firstname</code> Initiale du pr\u00e9nom string <code>lastname</code> Nom de famille string"},{"location":"partie3/deploiement/#configuration-du-provider","title":"Configuration du Provider","text":"<p>Le provider Databricks est configur\u00e9 avec l'authentification Azure AD :</p> <pre><code>provider \"databricks\" {\n  host               = var.workspace_url\n  azure_client_id     = var.sp_client_id\n  azure_client_secret = var.sp_secret_value\n  azure_tenant_id     = var.sp_tenant_id\n}\n</code></pre>"},{"location":"partie3/deploiement/#specifications-du-cluster","title":"Sp\u00e9cifications du Cluster","text":"<p>Le cluster est configur\u00e9 avec les param\u00e8tres suivants :</p> <pre><code>resource \"databricks_cluster\" \"cluster\" {\n  cluster_name            = \"databricks-cluster-${var.initial_firstname}${var.lastname}\"\n  spark_version           = \"15.4.x-scala2.12\"\n  node_type_id            = \"Standard_DS3_v2\"\n  autotermination_minutes = 60\n  spark_conf = {\n    \"spark.databricks.cluster.profile\" = \"singleUser\"\n  }\n  num_workers = 1\n}\n</code></pre>"},{"location":"partie3/deploiement/#parametres-du-cluster","title":"Param\u00e8tres du Cluster","text":"<ul> <li>Nom : Le nom du cluster est g\u00e9n\u00e9r\u00e9 automatiquement avec l'initiale du pr\u00e9nom et le nom de famille</li> <li>Version Spark : 15.4.x avec Scala 2.12</li> <li>Type de Node : Standard_DS3_v2</li> <li>Auto-termination : 60 minutes</li> <li>Nombre de Workers : 1</li> <li>Profil : singleUser</li> </ul>"},{"location":"partie3/deploiement/#deploiement","title":"D\u00e9ploiement","text":"<p>Pour d\u00e9ployer le cluster, ex\u00e9cutez les commandes suivantes :</p> <pre><code>terraform init\nterraform plan -var-file=\"terraform.tfvars\" -out=\"plan.tfplan\"\nterraform apply \"plan.tfplan\"\n</code></pre>"},{"location":"partie3/introduction/","title":"Objectif","text":"<p>Configurer Azure Databricks pour permettre \u00e0 l'\u00e9quipe Data Science d'analyser les donn\u00e9es, tout en mettant en \u0153uvre les mesures de s\u00e9curit\u00e9 appropri\u00e9es. </p> <p></p>"},{"location":"partie3/securite/","title":"S\u00e9curit\u00e9","text":"<ul> <li>L'authentification se fait via un Service Principal Azure</li> <li>Les secrets sont stock\u00e9s dans le fichier <code>terraform.tfvars</code> (\u00e0 ne pas versionner)</li> <li>Le cluster est configur\u00e9 en mode \"singleUser\" pour plus de s\u00e9curit\u00e9</li> </ul>"},{"location":"partie3/securite/#service-principal-databricks-sp_databricks_p1","title":"Service Principal Databricks (sp_databricks_p1)","text":"<p>Objectif : Gestion des acc\u00e8s pour Databricks</p> <pre><code>resource \"azuread_application\" \"sp_databricks_p1\" {\n  display_name = \"sp-databricks-${var.initial_firstname}${var.lastname}\"\n  owners       = [data.azuread_client_config.current.object_id]\n}\n</code></pre> <p>R\u00f4les attribu\u00e9s :     - Storage Blob Data Contributor</p> <pre><code>- Key Vault Secrets User\n\n- Key Vault Contributor\n\n- Storage Account Key Operator Service Role\n\n- Contributor (sur le Resource Group Databricks)\n</code></pre>"},{"location":"partie3/securite/#securisation-des-secrets","title":"S\u00e9curisation des Secrets","text":""},{"location":"partie3/securite/#gestion-des-mots-de-passe","title":"Gestion des Mots de Passe","text":"<p>Le mots de passe du SP : 1. G\u00e9n\u00e9r\u00e9 automatiquement 2. Stock\u00e9 dans Key Vault 3. Configur\u00e9 avec une date d'expiration (2025-05-05)</p> <pre><code>resource \"azuread_application_password\" \"sp_databricks_password\" {\n  application_id = azuread_application.sp_databricks_p1.id \n  end_date      = \"2025-05-05T23:59:59Z\"\n}\n</code></pre>"},{"location":"partie3/securite/#secret-scope-databricks","title":"Secret Scope Databricks","text":"<p>Un Secret Scope d\u00e9di\u00e9 est cr\u00e9\u00e9 pour Databricks :</p> <pre><code>resource \"databricks_secret_scope\" \"databricks_secret_scope\" {\n  name = \"databricks-secret-scope-${var.initial_firstname}-${var.lastname}\"\n  keyvault_metadata {\n    resource_id = azurerm_key_vault.kv.id\n    dns_name    = azurerm_key_vault.kv.vault_uri\n  }\n}\n</code></pre>"},{"location":"partie3/securite/#maintenance","title":"Maintenance","text":"<ul> <li>Le cluster s'arr\u00eate automatiquement apr\u00e8s 60 minutes d'inactivit\u00e9</li> <li>La mise \u00e0 jour du cluster peut se faire en modifiant les param\u00e8tres dans le code Terraform</li> <li>Les modifications doivent \u00eatre appliqu\u00e9es avec <code>terraform apply</code></li> </ul>"}]}